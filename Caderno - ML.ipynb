{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "129c31ee",
   "metadata": {},
   "source": [
    "# <font color=#FFCC66> Preprocessamento </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eaeff8",
   "metadata": {},
   "source": [
    "- df.shape\n",
    "- df.info()\n",
    "- df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e95ca6",
   "metadata": {},
   "source": [
    "## <font color=#33CC66> Categorização de Feature </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b440e0ea",
   "metadata": {},
   "source": [
    "### OneHotEncode ou GetDummies\n",
    "\n",
    "- Criação de uma feature para cada categoria\n",
    "\n",
    "```python\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "    hot = OneHotEncoder()\n",
    "    y_train = hot.fit_transform(y_train)\n",
    "    y_test = hot.transform(y_test)\n",
    "```\n",
    "\n",
    "### Label Encoder\n",
    "\n",
    "- A categorização se mantém em uma única feature, porém cada uma delas é atrelada a um valor numérico SEQUENCIAL\n",
    "- Tal ordenação pode gerar certos problemas de \"ordem\" entre as categorias \n",
    "- Normalmente os algorítimos baseados em distância sofrem com essa categorização (KNN, K-Means, Regressão Logística)\n",
    "\n",
    "Ex: Níveis de Escolaridade\n",
    "\n",
    "```python\n",
    "    df.col = df.col.replace[{'label1':0, 'label2':1, 'label3':2}]\n",
    "```\n",
    "\n",
    "### Discretização\n",
    "\n",
    "- Criar rótulos que agrupam as categorias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cfbd64",
   "metadata": {},
   "source": [
    "##  <font color=#33CC66> Feature Scaling </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c090d619",
   "metadata": {},
   "source": [
    "##### Mais sensíveis:  \n",
    "Otimização:\n",
    "- Regressão Linear\n",
    "- Regressao Logística\n",
    "- Redes Neurais\n",
    "\n",
    "Distância:\n",
    "- SVM\n",
    "- KNN\n",
    "- K-means\n",
    "\n",
    "##### Menos sensíveis:  \n",
    "- Arvore de Decisão\n",
    "- Randon Forest\n",
    "  \n",
    "#### Tipos\n",
    "##### Standardization (Padronização - Quantos desvios padrões da média)\n",
    "* <b> Sempre fitar o modelo DEPOIS do split do dataset </b>\n",
    "<br> Assim, não é vazado informação de teste para o treino\n",
    "\n",
    "```python\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    x_train_std = scaler.fit_transform(x_train) # z_scaler - O fit salva a média e o desvio padrão para aplicar a Padronização\n",
    "    x_val_std = scaler.transform(x_val) # aplicar a padronização\n",
    "```\n",
    "##### Normalization (Valor / Valor_Max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c92fbbf",
   "metadata": {},
   "source": [
    "##  <font color=#33CC66> Dimension Reduction </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445ab5ff",
   "metadata": {},
   "source": [
    "# <font color=#FFCC66> Estrutura de um Modelo de Machine Learning </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be25c92f",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1000/1*ZiYvylk60EY2XG7ck1lqJA.png\" width=500>\n",
    "\n",
    "- **Conjunto de dados de treino**: são os dados utilizados para a construção do modelo, os dados que o modelo utilizará \"para aprender\";\n",
    "\n",
    "\n",
    "- **Conjunto de dados de validação**: conjunto de dados usados para testar o modelo e aprimorar a sua performance, seja na seleção de hyperparâmetros/seleção de modelo;\n",
    "\n",
    "\n",
    "- **Treinamento do modelo**: é a etapa em que cálculos matemáticos são feitos para que a equação que descreve o modelo seja criada! É assim que \"o modelo aprende!\";\n",
    "\n",
    "\n",
    "- **Seleção de hiperparâmetros/seleção de modelo**: etapa em que os hiperperâmetros que constituem o modelo são selecionados. Aqui, técnicas como **grid search** e **cross validation** são muito importantes! Falaremos disso mais tarde.\n",
    "\n",
    "\n",
    "- **Conjunto de dados de teste**: conjunto de dados utilizado para testar o modelo após ele ter sido treinado. Essa é a melhor forma de simular o modelo em produção ou podemos dizer \"na vida real\", onde o nosso modelo será testado com dados que ele nunca viu;\n",
    "\n",
    "\n",
    "- **Avaliação**: forma de avaliar a performance do modelo. Há várias métricas e formas diferentes de avaliação, que conheceremos melhor mais tarde.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71376e28",
   "metadata": {},
   "source": [
    "## <font color=#33CC66> Particionamento de Base </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e656621",
   "metadata": {},
   "source": [
    "### Holdout (Split Train Test)\n",
    "\n",
    "```python\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X = df.drop(columns=target)\n",
    "    y = df.target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=0.3,\n",
    "                                                        random_state=42,\n",
    "                                                        stratify=y)\n",
    "```\n",
    "\n",
    "### Cross-Validation\n",
    "\n",
    "- Realiza k treinamentos (alternando a base de treinamento em k vezes)\n",
    "- Método de particionamento de dados iterativo\n",
    "- A base de treino é dividida entre treino e validação diversas vezes para garantir maior quantidade de ambiente de treino\n",
    "- Vantagens: garante que o desempenho do algoritmo será bom independente da seleção dos dados de validação\n",
    "- Comum para validar os parâmetros do modelo (Grid Search e Random Search)\n",
    "\n",
    "```python\n",
    "    from sklearn.model_selection import cross_validate\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "    clf = DecisionTreeClassifier(random_state= 42)\n",
    "    cv_results = cross_validate(clf, x_train, y_train, cv=5, scoring=['mean_squared_error', 'accuracy_score'], return_train_score= True)\n",
    "    print(cv_results['test_mean_squared_error'])\n",
    "    print(cv_results['train_accuracy_score'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c52fd4",
   "metadata": {},
   "source": [
    "## <font color=#33CC66> Tunagem de Modelo </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80f30b7",
   "metadata": {},
   "source": [
    "<b> ESTATÍSTICAMENTE O RANDOM SEARCH É MELHOR </b>\n",
    "<br>Isso, pois quando existem muitos hiperparam, acertar aleatóriamente os mais impactantes vale mais que rodar todos um por um\n",
    "\n",
    "\n",
    "* Hiperparâmetro: valores de configuração do modelo\n",
    "* Parâmetro: valores a serem aprendidos pelo modelo\n",
    "\n",
    "* Caputrar os valores de Hiperparâmetros\n",
    "    <br> model.get_params()\n",
    "* Primeiro utilizar a busca para <b>encontrar</b> os hiperparâmetros\n",
    "* Em seguida, utilizar eles para criar o modelo\n",
    "\n",
    "\n",
    "| Grid Search                             | Random Search                                     |\n",
    "|-----------------------------------------|---------------------------------------------------|\n",
    "| Preciso preparar e varrer todos valores | Varre alguns valores aleatoriamente               |\n",
    "| Alto custo de tempo                     | Menor custo de tempo, pois não vamos varrer todos |\n",
    "| Pode ser paralelizado                   | Pode ser paralelizado                             |\n",
    "|                                         | Podemos otimizar (Não só para esse método)        |\n",
    "\n",
    "\n",
    "\n",
    "### GridSearch\n",
    "```python\n",
    "    from sklearn.Neighbors import KNeighborsClassifier\n",
    "    from sklearn. import StandardScaler\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    model = KNeighborsClassifier()\n",
    "    X_std = scaler.fit_transform(X)\n",
    "    espaco_hiperparm = {\n",
    "        'n_neighbors': [13, 12, 11, 9, 5, 3, 1]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(model, espaco_hiperparm, cv=5)\n",
    "    search = grid_search.fit(X_std, y_train)\n",
    "    print(grid_search.best_params_)\n",
    "    display(pd.DataFrame(grid_search.cv_results_))    \n",
    "```\n",
    "\n",
    "### RandomSearch\n",
    "* n_iter : quantidade de iterações a se realizar pelo modelo\n",
    "\n",
    "```python\n",
    "    from sklearn.Neighbors import KNeighborsClassifier\n",
    "    import numpy as np\n",
    "    from sklearn. import StandardScaler\n",
    "    from sklearn.model_selection import RandomizeSearchCV\n",
    "\n",
    "    model = KNeighborsClassifier()\n",
    "    X_std = scaler.fit_transform(X)\n",
    "    espaco_hiperparm = {\n",
    "        'n_neighbors': np.arange(3, 11),\n",
    "        'p': np.arange(1, 3) # Para grau arbitrário é usado Minkowski com p = n\n",
    "    }\n",
    "\n",
    "    rand_search = RandomizeSearchCV(model, espaco_hiperparm, cv=5, n_iter=n)\n",
    "    search = rand_search.fit(X_std, y_train)\n",
    "    print(rand_search.best_params_)\n",
    "    display(pd.DataFrame(rand_search.cv_results_))\n",
    "\n",
    "    guardar_dados = csv.params e csv.mean_test_score\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48676361",
   "metadata": {},
   "source": [
    "## <font color=#33CC66> Métricas de Avaliação </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3567026e",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n",
    "```\n",
    "\n",
    "<img src=\"https://static.packt-cdn.com/products/9781838555078/graphics/C13314_06_05.jpg\" width=400>\n",
    "\n",
    "Visto isso, as seguintes métricas numéricas de avaliação são bastante comuns na avaliação de modelos de classificação:\n",
    "\n",
    "- Acurácia (Accuracy): porcentagem de classificações CORRETAS do modelo; <b> Predição Correta / Predição Total </b> (Problema com bases desbalanceadas)\n",
    "\n",
    "- Precisão (Precision): das respostas retornadas, quantas são relevantes? -- <b> Predição 1 / (Predição Correta 1 + Predição Incorreta 1) </b> (Foca no Falso Positivo)\n",
    "\n",
    "- Revocação/Sensibilidade (Recall/Sensitivity): das respostas relevantes, quantas são retornadas? -- <b> Predição 1 / (Predição Correta 1 + Predição Incorreta 0) </b> (Foca no Falso Negativo)\n",
    "\n",
    "- F1-Score: média harmônica de precision e recall. (Interessante como métrica única)\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1080/1*t1vf-ofJrJqtmam0KSn3EQ.png\" height=\"400\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b9927c",
   "metadata": {},
   "source": [
    "#  <font color=#FFCC66> Supervisionados </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbebe01",
   "metadata": {},
   "source": [
    "## Modelos de Classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f091eb",
   "metadata": {},
   "source": [
    "### Regressão Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ca9f6f",
   "metadata": {},
   "source": [
    "- Utilizado quando a clasificação é binária\n",
    "- Se apoia na probabilidade de uma função signoide e um threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b53065b",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "reg = LogisticRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdd0856",
   "metadata": {},
   "source": [
    "##### - Hiperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f274cf11",
   "metadata": {},
   "source": [
    " - Penalty\n",
    " - Max_iter\n",
    " - C\n",
    " - Solver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc8d1d9",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a30b16c",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(random_state=42,\n",
    "                             max_depth=n) # A profundidade da árvore evita overfiting\n",
    "dtc.get_params() # Apresentar como o modelo está parametrizado\n",
    "dtc.fit(X_train, y_train)\n",
    "y_pred = dtc.predict(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95921b4",
   "metadata": {},
   "source": [
    "##### - Hiperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847bdbd9",
   "metadata": {},
   "source": [
    " - Criterion\n",
    " - Max_depht\n",
    " - Min_samples_split\n",
    " - Min_samples_leaf\n",
    " - Max_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2da39c",
   "metadata": {},
   "source": [
    "#### **- Critério de Gini ou Entropia**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f9bf1f",
   "metadata": {},
   "source": [
    "##### **- Critério de Gini**\n",
    "\n",
    "A **impureza de Gini** mede o quão \"impuras\" são as folhas das árvores construídas após as quebras nos nós. O coeficiente é dado por:\n",
    "\n",
    "$$Gini(D) = 1 - \\sum{p_{i}^2}$$\n",
    "\n",
    "Onde $p_i$ são as proporções de separação do target em cada quebra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a12fb4f",
   "metadata": {},
   "source": [
    "- $G(\\text{p1}) = 1 - (\\frac{p1_1}{p1_t}^2 + \\frac{p1_2}{p1_t}^2)$\n",
    "\n",
    "    <br>\n",
    "- $G(\\text{p2}) = 1 - ( \\frac{p2_1}{p2_t}^2 + \\frac{p2_2}{p2_t}^2)$\n",
    "\n",
    "Ou seja, após a divisão, a impureza total passa a ser a média ponderada: \n",
    "\n",
    "- $G(\\text{médio-pós-divisão}) = \\frac{p1}{p_t} \\times G(\\text{p1}) + \\frac{p2}{p_t} \\times G(\\text{p2})$\n",
    "\n",
    "Assim, **a perda de impureza proporcionada pela quebra** dos dados segundo a feature **sexo** é de:\n",
    "\n",
    "- $\\Delta G_{\\text{sexo}} = G(\\text{pré-divisão}) - G(\\text{pós-divisão})$\n",
    "\n",
    "\n",
    "\n",
    "O **critério de Gini** consiste em **escolher a quebra que proporciona a maior perda de impureza**, ou, equivalentemente, **a maior purificação**. Portanto, quanto maior, melhor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1d5bf8",
   "metadata": {},
   "source": [
    "##### **- Critério de entropia**\n",
    "\n",
    "A **entropia** é uma quantidade definida em física e teoria da informação com o objetivo de quantificar **o grau de desordem de um sistema**, ou, equivalentemente, **o quanto de informação se tem sobre determinado sistema**.\n",
    "\n",
    "A entropia é dada por:\n",
    "\n",
    " $$E = -\\sum{p_{i} \\times \\log_{2}{p_{i}}}$$\n",
    " \n",
    " \n",
    "Onde $p_i$ são as proporções de separação do target em cada quebra.\n",
    "\n",
    "Aqui estaremos interessados **em como a impureza muda após as quebras**. \n",
    " \n",
    "Aqui também estaremos interessados **em como a entropia muda após as quebras**. Nosso objetivo será **maximizar o ganho de informação proporcionado pela quebra nos nós** -- mais precisamente, estamos interessados em determinar **qual é a quebra que proporciona o maior ganho de informação**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981696d6",
   "metadata": {},
   "source": [
    "- **Entropia antes da divisão**: \n",
    "\n",
    "    - $E(\\text{p1}) = -1 \\times (\\frac{p1_1}{p1_t} \\log_{2}\\frac{p1_1}{p1_t} + \\frac{p1_2}{p1_t} \\log_{2}\\frac{p1_2}{p1_t})$\n",
    "\n",
    "        <br>\n",
    "    - $E(\\text{p2}) = -1 \\times (\\frac{p2_1}{p2_t} \\log_{2}\\frac{p2_1}{p2_t} + \\frac{p2_2}{p2_t} \\log_{2}\\frac{p2_2}{p2_t})$\n",
    "    \n",
    "    A entropia ponderada após a divisão por **sexo** é:\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    - $E(\\text{pós-divisão}) = \\frac{p1}{p_t} \\times E(\\text{p1}) + \\frac{p2}{p_t} \\times E(\\text{p2})$\n",
    "    \n",
    "    Assim, o ganho de informação após a divisão por **sexo** é:\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    - $\\Delta E_{\\text{sexo}} = E(\\text{pré-divisão}) - E(\\text{pós-divisão})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079fa170",
   "metadata": {},
   "source": [
    "**Qual escolher?**\n",
    "- Calcular log é mais caro computacionalmente\n",
    "- A \"vantagem\" logaritmica é justamente quando o valor percorre uma gama grande de valores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ce48a8",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64105ac9",
   "metadata": {},
   "source": [
    "Algoritmo de Classificação com embasamento na distância entre as amostras.\n",
    "Dessa forma dentro de um raio de \"K\" vizinhos analisados é realizado a classificação da amostra nos labels disponíveis\n",
    "\n",
    "* Problemas com normalização por considerar distâncias\n",
    "* Sem aprendizado, a cada amostra nova o algoritmo é executado novamente\n",
    "\n",
    "```python\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors:int, metric:str)\n",
    "    knn.fit(x_train, y_train)\n",
    "    y_pred = knn.predict(y_test)\n",
    "    classification_report(y_test, y_pred)\n",
    "    confusion_matrix(y_test, y_pred)\n",
    "```\n",
    "\n",
    "#### Métricas de Distância\n",
    "* Minkowski (p=2) [Generalização da distância Euclidiana]\n",
    "* Euclidiano (p=2)\n",
    "* Manhatam (p=n)\n",
    "* Mahalanobis (p=2) [Normalização em relação à variância]\n",
    "* Chebyshev (p=infinito quando vertical)\n",
    "\n",
    "#### Otimizando o \"K\"\n",
    "* Testar a acurácia entre treino e validação/teste\n",
    "* Elbow Method (Focar na questão de minimização de erro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbebe01",
   "metadata": {},
   "source": [
    "## Modelos de Regressão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fa6c01",
   "metadata": {},
   "source": [
    "### Decision Tree Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cc14df",
   "metadata": {},
   "source": [
    "\n",
    "* Regressão é o método estatístico para estimar o relacionamento entre duas variáveis (dependente/alvo e independente/preditoras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5fa593",
   "metadata": {},
   "source": [
    "### KNN Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a72570",
   "metadata": {},
   "source": [
    "Realiza a regresssão considerando todas as features de X como a variável independente\n",
    "E a coluna y como variável dependente\n",
    "\n",
    "<b> A Métrica Padrão de Erro é R² </b>\n",
    "\n",
    "```python\n",
    "    from sklearn.neighbors import KNeighborsRegressor\n",
    "    from sklearn.metrics import r2_score\n",
    "\n",
    "    knn_reg = KNeighborsRegressor(n_neighbors = k)\n",
    "    knn_reg.fit(x_train, y_train)\n",
    "    y_pred = knn_reg.pred(x_val)\n",
    "    ## É possível buscar funções para plotar a relação do Valor Predito com o Real pelo seaborn\n",
    "    r2_score(y_test, y_pred)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b9927c",
   "metadata": {},
   "source": [
    "#  <font color=#FFCC66> Não Supervisionados </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbebe01",
   "metadata": {},
   "source": [
    "## Modelos de Clusterização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef17ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdd0bb10",
   "metadata": {},
   "source": [
    "#  <font color=#FFCC66> Data Visualization </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5633b1c0",
   "metadata": {},
   "source": [
    "## Pair Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea3d392",
   "metadata": {},
   "source": [
    "Função para comparar feature por feature e buscar as correlações da base\n",
    "\n",
    "**O parâmetro \"hue\" é o discretizador da curva, ou seja, o seu target**\n",
    "\n",
    "Dessa forma, é bom buscar o formato da distribuição da feature com ela mesma. Se as curvas do hue forem muito diferentes, podem trazer algum insight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128eaf32",
   "metadata": {},
   "source": [
    "- sns.pairplot(df, hue=label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39249489",
   "metadata": {},
   "source": [
    "## CountPlot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b139f129",
   "metadata": {},
   "source": [
    "- sns.countplot(feature, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766aacd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a381543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
